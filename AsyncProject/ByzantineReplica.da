import sys
import nacl.encoding
import nacl.signing
import nacl.hash
import uuid
import copy
import random
from random import randint
from nacl.bindings.utils import sodium_memcmp
import nacl.secret
import nacl.utils
import nacl
from nacl.public import PrivateKey, Box
import logging
import datetime
import time
import traceback
import time
import os
import itertools

#config_file_name = "stress10.txt"
timestamp = datetime.datetime.fromtimestamp(
    time.time()).strftime('%Y-%m-%d %H:%M:%S')


class Replica(process):

    # def decrypt_message(msg):
    def get_failure_workload():
        #output("my replica_id is "+str(replica_id))
        workload = config.get('failures['+str(configuration_id)+',' + str(replica_id) + ']')
        if workload is None:
            return

        workload = workload.split(';')
        trigger_failures = []
        for items in workload:
            items = items.strip()

            first_occur = items.find(",")
            second_occur = items.find(",", first_occur + 1)

            if second_occur == -1:
                trigger = items[0:first_occur].strip()
                failure = items[first_occur + 1:].strip()    

                open_brace_loc = trigger.find("(")
                trigger_name = trigger[0:open_brace_loc]
                trigger_name = trigger_name.strip()

                closed_brace_occurrence = trigger.find(")")

                client_id = None

                message_id = trigger[open_brace_loc + 1:closed_brace_occurrence]
                message_id = message_id.strip()
                
            else:
                trigger = items[0:second_occur].strip()
                failure = items[second_occur + 1:].strip()

                open_brace_loc = trigger.find("(")
                trigger_name = trigger[0:open_brace_loc]
                trigger_name = trigger_name.strip()

                comma_occurrence = trigger.find(",")
                closed_brace_occurrence = trigger.find(")")

                client_id = trigger[open_brace_loc + 1:comma_occurrence]
                client_id = client_id.strip()

                message_id = trigger[comma_occurrence + 1:closed_brace_occurrence]
                message_id = message_id.strip()
                # add_order_statement_to_order_proof_in_shuttle(trigger_name,client_id,message_id)

            open_brace_loc = failure.find("(")
            closed_brace_occurrence = failure.find(")")
            failure_name = failure[0:open_brace_loc]
            failure_param = failure[open_brace_loc + 1:closed_brace_occurrence]
            failure_name = failure_name.strip()
            if len(failure_param) == 0:
                failure_param = None
            #print(failure_name)

            trigger_dict = {}
            trigger_dict["trigger_name"] = trigger_name
            trigger_dict["client_id"] = client_id
            trigger_dict["message_id"] = message_id
            trigger_dict["failure_name"] = failure_name
            trigger_dict["failure_param"] = failure_param
            failure_triggers.append(trigger_dict)

            # print(failure)

    def setup(T: int,replica_Set: set, replica_Id: int,config_file: string,configuration_id:int):
        #self.replica_set_united = replica_Set
        self.T = T
        self.configuration_id = configuration_id
        self.Active = "Active"
        self.Immutable = "Immutable"
        self.client_public_keys = {}
        self.public_key = None
        self.config_file_name = config_file
        self.private_key = None
        self.data_object = {}
        self.replica_id = replica_Id
        #output("updating replica_id"+str(replica_id))
        self.mode = None
        self.result_cache = {}
        self.is_head_replica = False
        self.is_tail_replica = False
        self.replica_set = {}
        self.current_slot_number = 0
        self.result_cache = {}
        self.history = History()
        self.public_keys = None
        self.global_timer = {}
        self.client_forwarded_request_count = {}
        self.config = None
        self.failure_triggers = []
        self.switch = 1
        self.pending_change_operations = 0
        self.pending_change_results = 0
        self.pending_drop_result_stmts = 0
        self.pending_crash_stmts = 0
        self.pending_truncate_history_statements = 0
        self.pending_sleep_statements = 0
        self.pending_drop_stmts = 0
        self.pending_increment_slot_stmts = 0
        self.pending_extra_op_stmts = 0
        self.pending_invalid_order_stmts_signatures = 0
        self.pending_invalid_result_signatures = 0
        self.pending_drop_checkpoint_stmts = 0
        self.sleep_time_periods  = []
        self.send_acks_to_replicas = {}
        self.retransmit_acknowledged = 0
        self.current_checkpoint_proof = None
        self.checkpoint_id = 0
        self.last_served_request_for_a_client = {}
        self.caughtup_message = None
        self.pending_drop_result_stmts_failure_at_tail_replica = False
        self.pending_change_result_failure_at_tail_replica = False
        self.completed_checkpoint_id = 0

        #todo make active when olympus is doing configuration
        self.replica_state = self.Active#Active 0 implies IMMUTABLE
        self.head_replica_id = None
        self.tail_replica_id = None
        read_config()
        get_failure_workload()
        self.checkpointing_interval = get_check_pointing_interval("checkpt_interval")
        if self.checkpointing_interval is None:
            self.checkpointing_interval = -1
        
        self.logger = logging.getLogger("Replica " + str(replica_id))
        self.logger.setLevel(logging.INFO)
        self.olympus = None  # todo send it in constructor

        #handler = logging.FileHandler('_replica.log')
        handler = logging.FileHandler(str(timestamp) + '_replica.log')
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)

        #self.handler = logging.FileHandler('test.log')
        # self.handler.setLevel(logging.INFO)
        #self.formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        # self.handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        logger.info(" for replica_id " + str(replica_id)+" :-> \n"+str(failure_triggers) + "\n")
        
        if replica_Id == 0:
            self.head_replica_id = replica_Id
            self.is_head_replica = True
            self.replica_timeout = get_timeout("head_timeout")
        elif replica_Id == len(replica_Set) - 1:
            self.tail_replica_id = None
            self.is_tail_replica = True
            self.replica_timeout = get_timeout("nonhead_timeout")
        else:
            self.replica_timeout = get_timeout("nonhead_timeout")

        count = 0
        
        for temp_replica_id,replica in enumerate(replica_Set):
            self.replica_set[temp_replica_id] = replica
            if count == 0:
                self.head_replica = replica

            elif count == len(replica_Set) - 1:

                self.tail_replica = replica
            count = count + 1
        logger.info("replica_Set "+str(replica_set))
        #print("tail replica "+str(tail_replica))

    def decode_hash_and_verify(hash_digest, signed_message, public_key):
        #print("inside decode_hash_and_verify")
        try:
            new_digest = public_key.verify(signed_message)
            if sodium_memcmp(hash_digest, new_digest):
                return True
            else:
                print("decode_hash_and_verify-failed: original "+str(hash_digest))
                print("decode_hash_and_verify-failed: unsigned hash"+str(new_digest))

                return False
        except:
            logger.error(
                "nacl.exceptions.BadSignatureError: Signature was forged or corrupt.")
            #print("verification 1 failed")

        return False

        # print(hash_digest)
        # print(new_digest)
        # print("\n\n\n")

    def match_hash_with_head_replica(replica_signed_hash, replica_public_key, head_signed_hash, head_public_key):
        #print("inside match_hash_with_head_replica")
        try:
            replica_msg_digest = replica_public_key.verify(replica_signed_hash)
            head_msg_digest = head_public_key.verify(head_signed_hash)

            #print("replica_msg_digest "+str(replica_msg_digest) )
            #print("head_msg_digest "+str(head_msg_digest) )
            if sodium_memcmp(replica_msg_digest, head_msg_digest):
                return True
            else:
                return False
        except:
            logger.error(
                "nacl.exceptions.BadSignatureError: Signature was forged or corrupt")
            #print("verification 2 failed")

        return False

    def is_registered_client(client_id):
        if client_id in self.client_public_keys:
            logger.info("is_registered_client: client_id=%s is registered at replica_id=%s", str(
                client_id), str(replica_id))
            return True
        else:
            logger.info("is_registered_client: client_id=%s is NOT registered at replica_id=%s", str(
                client_id), str(replica_id))
            return False

    def check_in_result_cache(client_id, request_id):
        logger.info("checking if result is found in result cache for client_id:%s and request_id:%s at replica_id:%s", str(
            client_id), str(request_id), str(replica_id))
        cache_key = '00000'+str(client_id)+'11111' + str(request_id)
        #output("checking if result is found in result cache "+cache_key)
        if cache_key in result_cache:
            #output("found in cache at replica_id "+str(replica_id))
            logger.info(
                "check_in_result_cache:found %s in result cache", str(cache_key))
            #output("answer "+str(result_cache[cache_key]))
            return result_cache[cache_key]
        else:
            #output("not found in cache at"+str(replica_id))
            logger.info(
                "check_in_result_cache: %s is NOT in result cache", str(cache_key))
            return None

    def read_config():
        config = {}
        with open(self.config_file_name, 'r') as f:
            for line in f:
                if line[0] != '#':
                    (key, sep, val) = line.partition('=')
                    # if the line does not contain '=', it is invalid and hence ignored
                    if len(sep) != 0:
                        val = val.strip()
                        config[key.strip()] = int(
                            val) if str.isdecimal(val) else val
        self.config = config

    def get_timeout(timeout_key):
        #client_timeout = 3000
        timeout_val = config.get(timeout_key)
        timeout_val = int(timeout_val)
        timeout_val = timeout_val/1000
        return timeout_val

    def get_check_pointing_interval(check_point_key):
        #client_timeout = 3000
        return config.get(check_point_key)

    # addding a new valid client to clientinfo
    def receive(msg=('add_client_at_replica', public_key, client_id), from_=olympus):
        self.olympus = olympus
        # output('adding client in replica clientinfo at ' + str(self) +
        #	   ' client id is ' + str(client_id) + ' at clock ' + str(current_clock))
        logger.info("received: 'add_client_at_replica' with client_id:%s at replica:%s FROM Olympus", str(
            client_id), str(replica_id))
        self.client_public_keys[client_id] = public_key
        self.client_forwarded_request_count[client_id] = 0
        send(('client_registered_at_replica', client_id,replica_id), to=olympus)
        logger.info("sent: 'client_registered_at_replica'- client_id=%s,at replica:%s TO Olympus",
                    str(client_id), str(replica_id))

    def process_operation(operation):
        logger.info("replica_id=%s is processing operations", str(replica_id))
        opcode = operation['operation']
        if opcode == "put":
            key = operation["key"]
            value = operation["value"]
            self.data_object[key] = value
            return "Success"
        elif opcode == "get":
            key = operation["key"]
            if key not in data_object:
                return "Error"
            value = data_object[key]
            return value
        elif opcode == "slice":
            key = operation["key"]
            if key not in data_object:
                return "Error"
            index1 = int(operation["value1"])
            index2 = int(operation["value2"])
            value = data_object[key]
            value = value[index1:index2]
            self.data_object[key] = value
            return value
        elif opcode == "append":
            key = operation["key"]
            if key not in data_object:
                return "Error"
            value = operation["value"]
            #print("operation append value is"+str(operation["value"]))
            value = data_object[key] + value
            self.data_object[key] = value
            return "Success"

    def get_next_replica():
        logger.info("getting next replica:%s,len_of_replica_set:%s",str(replica_id+1),str(len(replica_set)))
        if replica_id == len(replica_set) - 1:
            return None  # tail_replica
        else:
            return replica_set[replica_id + 1]

    def get_prev_replica():
        #todo fix this log
        logger.info("getting prev replica:%s,len_of_replica_set:%s",str(replica_id -1),str(len(replica_set)))
        if replica_id == 0:
            return None  # head_replica
        else:
            return replica_set[replica_id - 1]

    def validate_result_shuttle(result_shuttle, client_id, request_id, replica_id):
        logger.info("validate_result_shuttle:validating result shuttle for client_id:%s,request_id:%s,replica_id:%s",str(client_id),str(request_id),str(replica_id))
        curr_order_proof = result_shuttle.get_order_proof_from_shuttle()
        #result_proofs = result_shuttle.get_result_proofs_from_shuttle()
        count_of_result_proofs = result_shuttle.get_count_of_result_proofs_in_shuttle()
        #output("len(result_proofs):, "+str(len(result_proofs)) +" client_id "+str(client_id)+" request_id "+str(request_id) +" replica_id "+str(replica_id))
        #output("len(replica_set): "+str(len(replica_set)) +" client_id "+str(client_id)+" request_id "+str(request_id) +" replica_id "+str(replica_id))

        logger.info("validate_result_shuttle: count_of_result_proofs "+str(count_of_result_proofs)+" len(replica_set): "+str(len(replica_set)) +" client_id "+str(client_id)+" request_id "+str(request_id) +" replica_id "+str(replica_id))

        if count_of_result_proofs != len(replica_set):
            send(('reconfigure_request',replica_id), to=olympus)
            logger.error("calling reconfig provable case of misbehaviour detected for client_id:%s,request_id:%s,replica_id:%s result proofs are invalid-count",
                         str(client_id), str(request_id), str(replica_id))
            return False

        head_replica_id = 0
        # validation result proofs
        head_replica_result_proof = result_shuttle.get_result_proof_of_replica(head_replica_id)

        head_replica_public_key = self.public_keys[head_replica_result_proof.replica_id]

        head_replica_hash_digest = head_replica_result_proof.get_result_hashed_value_from_result_proof()
        head_replica_signed_digest = head_replica_result_proof.get_result_signed_value_from_result_proof()


        for index in range(1, count_of_result_proofs):

            curr_result_proof = result_shuttle.get_result_proof_of_replica(head_replica_id)

            curr_replica_public_key = public_keys[curr_result_proof.replica_id]
            curr_result_proof_hash_digest = curr_result_proof.get_result_hashed_value_from_result_proof()
            curr_result_proof_signed_hash = curr_result_proof.get_result_signed_value_from_result_proof()
            if str(head_replica_result_proof.operation) != str(curr_result_proof.operation) or decode_hash_and_verify(curr_result_proof_hash_digest, curr_result_proof_signed_hash, curr_replica_public_key) is False or match_hash_with_head_replica(curr_result_proof_signed_hash, curr_replica_public_key, head_replica_signed_digest, head_replica_public_key) is False:
                #print("operation equality status "+str(str(head_replica_result_proof.operation) != str(curr_result_proof.operation)))
                #print("head op "+str(head_replica_result_proof.operation))
                #print("non head op "+str(head_replica_result_proof.operation))
                #output("need to call reconfig provable case of misbehaviour")
                #self.replica_state = self.Immutable
                send(('reconfigure_request',replica_id), to=olympus)
                logger.error("calling reconfig provable case of misbehaviour detected for client_id:%s,request_id:%s,replica_id:%s result proofs are invalid", str(
                    client_id), str(request_id), str(replica_id))
                return False
            # else:
            #	logger.info("ResultProof validation successful")
                # print("worked")

        count_of_order_statements = curr_order_proof.get_count_of_order_statements_from_order_proof()
        head_replica_order_stmt = curr_order_proof.get_order_statement_of_replica(head_replica_id)
        head_replica_public_key = public_keys[head_replica_order_stmt.replica_id]
        head_replica_hash_digest = head_replica_order_stmt.get_hash_of_order_statement()
        head_replica_signed_digest = head_replica_order_stmt.get_signed_hash_of_order_statement()

        #output("len(order_statements): "+str(len(order_statements)) +" client_id "+str(client_id)+" request_id "+str(request_id) +" replica_id "+str(replica_id))
        #output("len(replica_set): "+str(len(replica_set))+" client_id "+str(client_id)+" request_id "+str(request_id) +" replica_id "+str(replica_id))

        if count_of_order_statements != len(replica_set):
            send(('reconfigure_request',replica_id), to=olympus)
            logger.error("calling reconfig provable case of misbehaviour detected for client_id:%s,request_id:%s,replica_id:%s order_statements are invalid-count",
                         str(client_id), str(request_id), str(replica_id))
            return False

        for index in range(1, count_of_order_statements):

            curr_order_statement = curr_order_proof.get_order_statement_of_replica(index)

            curr_replica_public_key = public_keys[curr_order_statement.replica_id]
            curr_order_stmt_hash_digest = curr_order_statement.get_hash_of_order_statement()
            curr_order_stmt_signed_hash = curr_order_statement.get_signed_hash_of_order_statement()

            if (decode_hash_and_verify(curr_order_stmt_hash_digest, curr_order_stmt_signed_hash, curr_replica_public_key) is False) or (match_hash_with_head_replica(curr_order_stmt_signed_hash, curr_replica_public_key, head_replica_signed_digest, head_replica_public_key) is False):
                send(('reconfigure_request',replica_id), to=olympus)
                logger.error("calling reconfig provable case of misbehaviour detected for client_id:%s,request_id:%s,replica_id:%s order_statements are invalid-count",
                             str(client_id), str(request_id), str(replica_id))
                return False
        # validation of ordered proofs

    def change_operation_failure(client_request,client_id,request_id):
        output("changing operation for client_id" + str(client_id) +" request_id " + str(request_id) + " replica_id " + str(replica_id))
        self.pending_change_operations = self.pending_change_operations - 1
        operation_dict = {}
        operation_dict["operation"] = "get"
        operation_dict["key"] = "x"
        operation_dict["value"] = None

        logger.warning("changing operation for client_id :%s,request_id:%s,replica_id:%s,new operation:%s", str(client_id) ,str(request_id), str(replica_id),str(operation_dict))
        client_request.set_operation(operation_dict)
        return operation_dict

    def increment_slot_number_failure():
        
        while self.pending_increment_slot_stmts > 0:
            logger.warning("increment_slot: incrementing slot number for the head_replica")
            self.current_slot_number = self.current_slot_number + 1
            self.pending_increment_slot_stmts = self.pending_increment_slot_stmts - 1

    def sleep_failure():
        while self.pending_sleep_statements > 0:
            sleep_period = self.sleep_time_periods[0]
            del self.sleep_time_periods[0]
            #print("sleep_failure: replica_id: "+str(replica_id)+"sleeping for a period of "+str(sleep_period)+" milli seconds ")
            logger.warning(" sleep_failure: replica_id:%s sleeping for a period of %s milli seconds ",str(replica_id),str(sleep_period))
            self.pending_sleep_statements = self.pending_sleep_statements - 1
            sleep_period = int(sleep_period)
            sleep_period = sleep_period/1000
            current_time = time.time()
            time.sleep(sleep_period)
            new_time = time.time()
            logger.warning("replica_id:%s slept for %s milli seconds and is now awake ",str(replica_id),str(sleep_period))

    def crash_failure():
        logger.warning("crash_failure: crashing the replica %s",str(replica_id))
        self.pending_crash_stmts = self.pending_crash_stmts - 1
        os._exit(-1)

    def extra_op_failure():
        logger.warning("extra_op_failure: adding malicious operation put('a','a') to the replica's running state %s",str(replica_id))
        self.pending_extra_op_stmts = self.pending_extra_op_stmts - 1
        malicious_key = 'a'
        malicious_value = 'a'
        self.data_object[malicious_key] = malicious_value
       
    def drop_failure(msg,msg_id,special_msg=""):
        self.pending_drop_stmts = self.pending_drop_stmts - 1
        logger.warning("drop_failure: dropping the incoming msg:%s,with %s_id:%s "+special_msg,str(msg),str(msg),str(msg_id))


    def invalid_result_signature_failure(client_id,request_id,result_shuttle):
        self.pending_invalid_result_signatures = self.pending_invalid_result_signatures - 1
        curr_result_stmt_signed_msg = result_shuttle.get_result_proof_of_replica(replica_id).get_result_signed_value_from_result_proof()
        tampered_signed_msg = get_tampered_signed_msg(curr_result_stmt_signed_msg) 
        result_shuttle.get_result_proof_of_replica(replica_id).set_result_signed_value_in_result_proof(tampered_signed_msg)
        # output("invalid_result_sig: failure detected for client_id" + str(client_id) +
        #        " request_id " + str(request_id) + " replica_id " + str(replica_id))
        logger.warning("invalid_result_sig: failure detected for client_id:%s,request_id:%s,replica_id:%s", str(client_id) ,
               str(request_id), str(replica_id))

    def invalid_order_statement_signature_failure(client_id,request_id,result_shuttle):
        logger.warning("invalid_order_sig: failure detected for client_id:%s,request_id:%s,replica_id:%s", str(client_id) ,
               str(request_id), str(replica_id))
        # output("invalid_order_sig: failure detected for client_id" + str(client_id) +
        #        " request_id " + str(request_id) + " replica_id " + str(replica_id))

        self.pending_invalid_order_stmts_signatures = self.pending_invalid_order_stmts_signatures - 1
        
        order_stmt = result_shuttle.get_order_proof_from_shuttle().get_order_statement_of_replica(replica_id)
        curr_order_stmt_signed_msg = order_stmt.get_signed_hash_of_order_statement()
        tampered_signed_msg = get_tampered_signed_msg(curr_order_stmt_signed_msg) 
        order_stmt.set_signed_hashed_value_in_order_statement(tampered_signed_msg)

    def drop_checkpoint_stmts_failure(completed_checkpoint_proof,checkpoint_identifier):
        self.pending_drop_checkpoint_stmts = self.pending_drop_checkpoint_stmts - 1
        #output("drop_checkpt_stmts: failure detected, dropping the t+1 check point stmts for checkpoint_id: " + str(checkpoint_identifier) + " replica_id " + str(replica_id))
        logger.warning("dropping thr t+1 check point stmts for checkpoint_id: %s,replica_id:%s", str(checkpoint_identifier), str(replica_id))
        for rep_id in range(0,self.T + 1):
            completed_checkpoint_proof.remove_checkpoint_proof_at_replica_id(rep_id)

    def change_result_in_result_shuttle_failure(client_id,request_id,result_shuttle):
        #output("changing result for client_id" + str(client_id) +" request_id " + str(request_id) + " replica_id " + str(replica_id))
        logger.warning("changing result to 'OK' message client_id:%s,request_id:%s,replica_id:%s", str(client_id) ,
               str(request_id), str(replica_id))
        self.pending_change_results = self.pending_change_results - 1
        tampered_result = "OK"
        tampered_result_hash = get_hash(tampered_result)
        result_shuttle.get_result_proof_of_replica(replica_id).set_result_hashed_value_in_result_proof(tampered_result_hash)

    def drop_result_statement_of_head_replica_failure(client_id,request_id,result_shuttle):
        #output("dropping result stmt of head_replica  for client_id" + str(client_id) +" request_id " + str(request_id) + " replica_id " + str(replica_id))
        logger.warning("dropping result stmt of head_replica client_id:%s,request_id:%s,replica_id:%s", str(client_id) ,
               str(request_id), str(replica_id))

        self.pending_drop_result_stmts = self.pending_drop_result_stmts - 1
        #drop_result_proof_trigger = True
        logger.warning("drop_result_statement_of_head_replica_failure: before dropping result_shuttle count_of_result_proofs "+str(result_shuttle.get_count_of_result_proofs_in_shuttle()))
        result_shuttle.drop_result_proof_from_shuttle(head_replica_id)
        logger.warning("drop_result_statement_of_head_replica_failure: after dropping result_shuttle count_of_result_proofs "+str(result_shuttle.get_count_of_result_proofs_in_shuttle()))

    def receive(msg=('wedged_request',wedge_request_id),from_=olympus):
        logger.info("wedged_request:inside wedged_request at "+str(replica_id))
        wedge_request_failures = get_pending_failures_if_exists(None, wedge_request_id, "wedge_request")
        for wedge_request_failure in wedge_request_failures:
            if wedge_request_failure is not None:
                logger.info("Trigger Exists:  in  replica=%s, trigger_name=wedged_request with wedge_request_id=%s, failure_to_be_executed=%s", str(
                    replica_id), str(wedge_request_id), str(wedge_request_failure["failure_name"]))
                update_failure_count(str(wedge_request_failure["failure_name"]),wedge_request_failure["failure_param"])

                if self.pending_extra_op_stmts > 0:
                    extra_op_failure()

                if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                    increment_slot_number_failure()

                if self.pending_drop_stmts > 0:
                    drop_failure("wedged_request",wedge_request_id)
                    return 

                if self.pending_crash_stmts > 0:
                    crash_failure()

                if self.pending_sleep_statements > 0:
                    sleep_failure()


        logger.info("wedged_request: received wedged request FROM olympus changing the replica status to Immutable")
        self.replica_state = self.Immutable#changing the replica status to immutable
        logger.info("wedged_statement_from_replica: sending wedge statement to olympus making itself immutable replica_state:%s",str(self.replica_state))
        replica_history = copy.deepcopy(self.history)
        logger.info("wedged_request: completed_checkpoint_id  "+str(self.completed_checkpoint_id)+" at replica_id "+str(replica_id))
        wedged_statement = WedgedStatement(replica_history,current_checkpoint_proof,self.completed_checkpoint_id)

        logger.warning("pre-truncate_history-failure history order_proofs at replica_id :"+str(replica_id)+" is "+str(wedged_statement.get_history_from_wedged_statement().get_order_proofs()))

        #next_replica = get_next_replica()
        if self.pending_truncate_history_statements > 0: 
            self.pending_truncate_history_statements = self.pending_truncate_history_statements - 1
            #output("truncate_history: failure detected, omitting the last entry of the wedged statement wedge_request_id " + str(wedge_request_id) + " replica_id " + str(replica_id))
            logger.warning("truncate_history: failure detected, omitting the last entry of the wedged statement wedge_request_id :%s,replica_id:%s", str(wedge_request_id), str(replica_id))
            wedged_statement.get_history_from_wedged_statement().omit_last_entry_of_history()     
            logger.warning("post-truncate_history-failure history order_proofs at replica_id :"+str(replica_id)+" is "+str(wedged_statement.get_history_from_wedged_statement().get_order_proofs()))


        
        send(('wedged_statement_from_replica',wedged_statement,replica_id), to=olympus)

    def receive(msg=('send_retransmitted_status',cache_key,sender_replica_id),from_=valid_replica):
        logger.info("send_retransmitted_status: received from replica_id:%s",str(sender_replica_id))
        self.send_acks_to_replicas[cache_key] = True
        send(('acknowledge_retransmission',),to=valid_replica)
        logger.info("send_retransmitted_status: acknowledged replica_id:%s",str(sender_replica_id))

        #print(str(cache_key in send_acks_to_replicas)+" replica_id "+str(replica_id) + str(send_acks_to_replicas))

    def receive(msg=('acknowledge_retransmission',),from_=tail_replica):
        logger.info("acknowledge_retransmission: acknowledged at replica_id:%s",str(replica_id))
        self.retransmit_acknowledged = 2
        #print(str(cache_key in send_acks_to_replicas)+" replica_id "+str(replica_id) + str(send_acks_to_replicas))



    def receive(msg=('truncate_history_till_check_point',completed_checkpoint_proof,checkpoint_identifier),from_=prev_replica):
        
        logger.info("truncate_history_till_check_point with complete_checkpoint_identifier "+str(checkpoint_identifier)+" at replica_id "+str(replica_id))
        self.current_checkpoint_proof = copy.deepcopy(completed_checkpoint_proof)    
        completed_checkpoint_failures = get_pending_failures_if_exists(None, checkpoint_identifier, "completed_checkpoint")
        for completed_checkpoint_failure in completed_checkpoint_failures:
            if completed_checkpoint_failure is not None:
                logger.info("Trigger Exists: in  replica=%s, trigger_name=completed_checkpoint with completed_checkpoint_id=%s, failure_to_be_executed=%s", str(
                    replica_id), str(checkpoint_identifier), str(completed_checkpoint_failure["failure_name"]))
                update_failure_count(str(completed_checkpoint_failure["failure_name"]),completed_checkpoint_failure["failure_param"])

                if self.pending_extra_op_stmts > 0:
                    extra_op_failure()

                if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                    increment_slot_number_failure()

                if self.pending_drop_stmts > 0:
                    drop_failure("completed_checkpoint_failure",checkpoint_identifier)
                    return

                if self.pending_crash_stmts > 0:
                    crash_failure()

                if self.pending_sleep_statements > 0:
                    sleep_failure()


        replica_history = self.history
        slot_ids = replica_history.get_next_slot_ids(checkpoint_identifier,checkpointing_interval)
        #order_proofs = replica_history.get_order_proofs()
        for slot_id in slot_ids:
            logger.info("truncate_history_till_check_point: removing order_proof at slot_id "+str(slot_id)+" replica_id "+str(replica_id))
            replica_history.remove_order_proof_at_slot(slot_id)

        if self.pending_drop_checkpoint_stmts > 0:
            drop_checkpoint_stmts_failure(completed_checkpoint_proof,checkpoint_identifier)
        self.completed_checkpoint_id = self.completed_checkpoint_id + 1
        #print("replica_history.get_order_proofs()" +str(replica_history.get_order_proofs()) +" at replica_id "+str(replica_id))
        if self.is_head_replica is False:
            prev_replica = get_prev_replica()        
            send(('truncate_history_till_check_point',completed_checkpoint_proof,checkpoint_identifier), to=prev_replica)
        else:
            #print("truncation successfully done at all replicas replica_id:"+str(replica_id))
            logger.info("truncation successfully done at all replicas replica_id:"+str(replica_id))

    def validate_check_point_proofs(checkpoint_proof,checkpoint_identifier):
        prev_replica_id = replica_id - 1
        
        hash_of_running_state_prev_replica = checkpoint_proof.get_hash_of_running_state_of_replica(prev_replica_id) 
        signed_hash_of_running_state_prev_replica = checkpoint_proof.get_signed_hash_of_running_state_of_replica(prev_replica_id)
        public_key_of_prev_replica = self.public_keys[prev_replica_id]

        hash_of_running_state_current_replica = checkpoint_proof.get_hash_of_running_state_of_replica(replica_id)
        signed_hash_of_running_state_current_replica = checkpoint_proof.get_signed_hash_of_running_state_of_replica(replica_id)
        public_key_of_current_replica = self.public_keys[replica_id]

        if decode_hash_and_verify(hash_of_running_state_prev_replica,signed_hash_of_running_state_prev_replica,public_key_of_prev_replica) is False or match_hash_with_head_replica(signed_hash_of_running_state_prev_replica,public_key_of_prev_replica,signed_hash_of_running_state_current_replica,public_key_of_current_replica) is False:
            return False
        else:
            logger.info("checkpointproof validation is done at replica_id:%s",str(replica_id))
            return True

    def receive(msg=('initiate_checkpointing',checkpoint_proof,checkpoint_identifier),from_ = prev_replica):
        if checkpoint_identifier != self.checkpoint_id:
            send(('reconfigure_request',replica_id), to=olympus)
            logger.error("initiate_checkpointing:calling reconfig provable case of misbehaviour detected for checkpoint_identifier:%s,replica_id:%s checkpoint_identifier is invalid",
                         str(checkpoint_identifier),str(replica_id))
            return

        await((self.current_slot_number) % checkpointing_interval == 0)
        logger.info("initiate_checkpointing:performing checkpoining checkpoint_identifier "+str(checkpoint_identifier))
        checkpoint_failures = get_pending_failures_if_exists(None, checkpoint_identifier, "checkpoint")
        logger.info("initiate_checkpointing:performing checkpoining checkpoint_identifier "+str(checkpoint_identifier)+" after getting pending failures")
        for checkpoint_failure in checkpoint_failures:
            if checkpoint_failure is not None:
                logger.info("Trigger Exists: in  replica=%s, trigger_name=checkpoint with checkpoint_id=%s, failure_to_be_executed=%s", str(
                    replica_id), str(checkpoint_identifier), str(checkpoint_failure["failure_name"]))
                update_failure_count(str(checkpoint_failure["failure_name"]),checkpoint_failure["failure_param"])

                if self.pending_extra_op_stmts > 0:
                    extra_op_failure()

                if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                    increment_slot_number_failure()

                if self.pending_drop_stmts > 0:
                    #print("Executing drop_failure at replica_id:"+str(replica_id)+",checkpoint_identifier:"+str(checkpoint_identifier))
                    drop_failure("checkpoint_failure",checkpoint_identifier)
                    return

                if self.pending_crash_stmts > 0:
                    crash_failure()

                if self.pending_sleep_statements > 0:
                    sleep_failure()

        logger.info("initiate_checkpointing:performing checkpoining checkpoint_identifier "+str(checkpoint_identifier)+" after processing pending failures")
        hash_of_running_state,signed_hash_of_running_state = get_checkpoint_proof(checkpoint_identifier,checkpointing_interval)
        checkpoint_proof.add_to_check_point_proof(hash_of_running_state,signed_hash_of_running_state,replica_id)
        next_replica = get_next_replica()

        logger.info("initiate_checkpointing:performing checkpoining checkpoint_identifier "+str(checkpoint_identifier)+" ready to send to next replica")

        if self.is_head_replica is False: 
            if validate_check_point_proofs(checkpoint_proof,checkpoint_identifier) is False:
                logger.error("initiate_checkpointing:checkpoint validation failed, need to call reconfig provable case of misbehaviour detected at replica_id:%s ,checkpoint_identifier:%s", str(replica_id),str(checkpoint_identifier))

        self.checkpoint_id = self.checkpoint_id + 1
        if self.is_tail_replica is False:
            
            send(('initiate_checkpointing',checkpoint_proof,checkpoint_identifier), to=next_replica)
        else:
            #send checkpointing completed status to replica for
            #send(('checkpointing_completed',),to=head_replica)
            send(('truncate_history_till_check_point',checkpoint_proof,checkpoint_identifier), to=self)

    def get_checkpoint_proof(checkpoint_identifier,checkpointing_interval):
        replica_history = self.history
        running_state = ""
        order_proofs = replica_history.get_order_proofs()
        slot_ids = replica_history.get_next_slot_ids(checkpoint_identifier,checkpointing_interval)

        logger.info("get_checkpoint_proof:performing get_checkpoint_proof with slot_ids "+str(slot_ids)+" with checkpoint_identifier"+str(checkpoint_identifier)+" and checkpointing_interval "+str(checkpointing_interval))
        for slot_id in slot_ids:
            order_proof_for_each_slot = replica_history.get_order_proof_at_slot(slot_id)
            #print("order_proof_for_each_slot "+str(order_proof_for_each_slot))
            order_statements = order_proof_for_each_slot.get_order_statements_from_order_proof()
            #print("order_statements "+str(order_statements))
            replica_order_statement = order_statements[replica_id]
            running_state = running_state + replica_order_statement.get_order_statement_as_string()
        #print(running_state)
        hash_of_running_state, signed_hash_of_running_state = encode_hash(running_state, private_key)
        #print("hash_of_running_state"+str(hash_of_running_state))
        #print(signed_hash_of_running_state+str(signed_hash_of_running_state))
        return hash_of_running_state,signed_hash_of_running_state

    # def receive(msg=('checkpointing_completed',),from_=tail_replica):
    #     print("process terminated replica_id"+str(replica_id))
    #     self.last_check_pointing_successfully completed


    def receive(msg=('terminate_replica',),from_=olympus):
        print("process terminated replica_id"+str(replica_id))
        os._exit(-1)
        #replica_history = self.history
        #order_proofs = replica_history.get_order_proofs()
        #print("replica_id: "+str(replica_id)+" order_proofs: ",str(order_proofs))

    def receive(msg=('print_order_proofs',),from_=client):
        replica_history = self.history
        order_proofs = replica_history.get_order_proofs()
        logger.info("replica_id: "+str(replica_id)+" order_proofs: ",str(order_proofs))

    #def receive(msg=('perform_operation', client_id, request_id, operation, client_process, prev_order_statement, result, result_shuttle, retransmitted, retransmit_id)):
    def receive(msg=('perform_operation', client_request, result, result_shuttle,next_slot_number),from_=valid_process):
        print("\n\n next_slot_number from:"+str(next_slot_number) + " current_slot_number "+str(self.current_slot_number)+" at replica_id "+str(replica_id))
        client_id = client_request.get_client_id()
        request_id = client_request.get_request_id()
        operation = client_request.get_operation()
        client_process = client_request.get_client_process_info()
        retransmitted = client_request.get_retransmitted_status()
        retransmit_id = client_request.get_retransmit_id()

        #print(":here2 "+str(client_id)+" request_id "+str(request_id)+" operation "+str(operation))
        client_public_key = client_public_keys[client_id]
        #print(":here3 from:"+str(valid_process))
        hash_of_client_request = client_request.get_hash_of_client_request()
        signed_hash_of_client_request = client_request.get_signed_hash_of_client_request()


        logger.info("received: 'perform_operation' with retransmit_id=%s , client_id=%s, request_id=%s, operation=%s ,current_slot_number=%s",str(retransmit_id) ,str(
            client_id), str(request_id), str(operation),str(current_slot_number)+" received from "+str(valid_process))


        if self.replica_state == self.Immutable:
            logger.warning("'perform_operation' is ignored by head_replica with retransmit_id=%s , client_id=%s, request_id=%s, operation=%s ,current_slot_number=%s",str(retransmit_id) ,str(
            client_id), str(request_id), str(operation),str(current_slot_number))
            return


        if next_slot_number is not None and  decode_hash_and_verify(hash_of_client_request,signed_hash_of_client_request,client_public_key) is False :
            logger.error("perform_operation:client_request signature mismatch calling reconfig provable case of misbehaviour detected for client_id:%s,request_id:%s,replica_id:%s ",
                         str(client_id), str(request_id), str(replica_id))

            send(('reconfigure_request',replica_id), to=olympus)
            logger.info("reconfigure_request: 'perform_operation' with retransmit_id=%s , client_id=%s, request_id=%s, operation=%s ,current_slot_number=%s",str(retransmit_id) ,str(client_id), str(request_id), str(operation),str(current_slot_number))

            return


        if next_slot_number is not None and next_slot_number != current_slot_number :
            logger.error("perform_operation: slot_number mismatch  expected_slot:%s actual slot:%s calling reconfig provable case of misbehaviour detected for client_id:%s,request_id:%s,replica_id:%s ",str(current_slot_number),str(next_slot_number),str(client_id), str(request_id), str(replica_id))

            send(('reconfigure_request',replica_id), to=olympus)
            return




        #testing retransmit case when the request completely failed and forwarded request is procecessed
        # if int(client_id) == 0 and int(request_id) == 1 and int(replica_id) == 0 and retransmitted is None:
        #     return

        if is_registered_client(client_id) is False:
            # error case
            logger.warning("MALICIOUS client found")
        else:
                
            logger.info("replica_id=%s is processing operation=%s requested by client_id=%s", str(
                replica_id), str(operation), str(client_id))
            #output("client processing operation at replica_id: "+str(replica_id))

            if retransmitted is True:
                self.client_forwarded_request_count[client_id] = self.client_forwarded_request_count[client_id] + 1            
                forwarded_request_id = self.client_forwarded_request_count[client_id]
                #print("forwarded_request_id "+str(forwarded_request_id))
                pending_failures = get_pending_failures_if_exists(client_id, forwarded_request_id, "forwarded_request")

                for pending_failure in pending_failures:
                    if pending_failure is not None:
                        logger.info("Trigger Exists:  in  replica=%s, trigger_name=forwarded_request with client_id=%s, request_id=%s, failure_to_be_executed=%s", str(
                            replica_id), str(client_id), str(request_id), str(pending_failure["failure_name"]))
                        update_failure_count(str(pending_failure["failure_name"]),pending_failure["failure_param"])
                
                        if self.pending_extra_op_stmts > 0:
                            extra_op_failure()

                        if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                            increment_slot_number_failure()

                        if self.pending_drop_stmts > 0:
                            special_msg = "in replica_id "+str(replica_id)+" in client_id "+str(client_id)
                            drop_failure("forwarded_request",forwarded_request_id,special_msg)
                            return

                        if self.pending_crash_stmts > 0:
                            crash_failure()

                        if self.pending_sleep_statements > 0:
                            sleep_failure()

            cache_key = '00000'+str(client_id)+'11111' + str(request_id)
            
            if cache_key in result_cache and result_cache[cache_key] is True:

                logger.info("operation sent to replica_id=%s  operation=%s requested by client_id=%s and request_id:%s is duplicate", str(
                    replica_id), str(operation), str(client_id), str(request_id))
                # if the operation is already scheduled ignore the request
                pass
                # todo
            elif self.is_head_replica is True:

                client_request_failures = get_pending_failures_if_exists(client_id, request_id + retransmit_id, "client_request")
                for client_request_failure in client_request_failures:
                    if client_request_failure is not None:
                        logger.info("Trigger Exists:  in  replica=%s, trigger_name=client_request with client_id=%s, request_id=%s, failure_to_be_executed=%s", str(
                            replica_id), str(client_id), str(request_id), str(client_request_failure["failure_name"]))
                        update_failure_count(str(client_request_failure["failure_name"]),client_request_failure["failure_param"])

                        if self.pending_extra_op_stmts > 0:
                            extra_op_failure()

                        if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                            increment_slot_number_failure()

                        if self.pending_drop_stmts > 0:
                            special_msg = "in replica_id "+str(replica_id)+" in client_id "+str(client_id)
                            drop_failure("client_request",request_id,special_msg)
                            return

                        if self.pending_crash_stmts > 0:
                            crash_failure()

                        if self.pending_sleep_statements > 0:
                            sleep_failure()

                shuttle_failures = get_pending_failures_if_exists(
                    client_id, request_id + retransmit_id, "shuttle")
                for shuttle_failure in shuttle_failures:
                    if shuttle_failure is not None:
                        logger.info("Trigger Exists:  in  replica=%s, trigger_name=shuttle with client_id=%s, request_id=%s, failure_to_be_executed=%s", str(
                            replica_id), str(client_id), str(request_id), str(shuttle_failure["failure_name"]))
                        update_failure_count(str(shuttle_failure["failure_name"]),shuttle_failure["failure_param"])

                        if self.pending_extra_op_stmts > 0:
                            extra_op_failure()

                        if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                            increment_slot_number_failure()

                        if self.pending_drop_stmts > 0:
                            special_msg = "in replica_id "+str(replica_id)+" in client_id "+str(client_id)
                            drop_failure("shuttle_failure",request_id,special_msg)
                            return

                        if self.pending_crash_stmts > 0:
                            crash_failure()

                        if self.pending_sleep_statements > 0:
                            sleep_failure()

                result_cache[cache_key] = True
                result = process_operation(operation)

                order_proof = OrderProof(
                    current_slot_number, operation, replica_id)
                #print("head_replica")
                order_statement = OrderStatement(current_slot_number, operation, replica_id, self.private_key,client_id,request_id)
                order_proof.add_order_statment(replica_id,order_statement)

                history.add_order_proof_to_history(current_slot_number,order_proof)
                result_proof = ResultProof(operation, replica_id, result, self.private_key)
                result_shuttle = Shuttle(current_slot_number, operation)
                result_shuttle.add_result_proof_to_shuttle(replica_id,result_proof)
                result_shuttle.add_order_statement_to_order_proof_in_shuttle(replica_id,order_statement)


                self.last_served_request_for_a_client[client_id] = ResultCache(client_id,request_id,result,replica_id,self.private_key,operation)
                logger.info("last_served_request_for_a_client: replica_id:%s,request_id:%s",str(replica_id),str(request_id))
                

                if self.pending_invalid_result_signatures > 0:
                    invalid_result_signature_failure(client_id,request_id,result_shuttle)

                if self.pending_invalid_order_stmts_signatures > 0:
                    invalid_order_statement_signature_failure(client_id,request_id,result_shuttle)

                if self.pending_change_operations > 0:
                    operation = change_operation_failure(client_request,client_id,request_id)

                next_replica = get_next_replica()
                send(('perform_operation', client_request,result, result_shuttle, current_slot_number), to=next_replica)


                logger.info("sent: 'perform_operation' TO next_replica=%s, at head_replica with client_id=%s, request_id=%s, operation=%s, sending to %s", str(
                    replica_id + 1), str(client_id), str(request_id), str(operation),str(next_replica))

                self.current_slot_number = self.current_slot_number + 1

                if self.current_slot_number % checkpointing_interval == 0:
                    #pass
                    #print()
                    #hash_of_running_state,signed_hash_of_running_state = get_checkpoint_proof()
                    checkpoint_proof = CheckPointProof(checkpoint_id,current_slot_number - checkpointing_interval, current_slot_number - 1)
                    #todo await for prev checkpoint before sendinf request for next check point
                    #check_point_proof.add_to_check_point_proof(hash_of_running_state,signed_hash_of_running_state)
                    #next_replica = get_next_replica()
                    send(('initiate_checkpointing',checkpoint_proof,checkpoint_id), to=self)
                    

            else:

                # if int(client_id) == 0 and int(request_id) == 0 and int(replica_id) == 1 and retransmitted is None:
                #    work()
                #    work()
                #reading the failures and addding to the failures
                client_request_failures = get_pending_failures_if_exists(
                    client_id, request_id + retransmit_id, "client_request")
                for client_request_failure in client_request_failures:
                    if client_request_failure is not None:
                        logger.info("Trigger Exists:  in  replica=%s, trigger_name=client_request with client_id=%s, request_id=%s, failure_to_be_executed=%s", str(
                            replica_id), str(client_id), str(request_id), str(client_request_failure["failure_name"]))
                        update_failure_count(str(client_request_failure["failure_name"]),client_request_failure["failure_param"])

                        if self.pending_extra_op_stmts > 0:
                            extra_op_failure()

                        if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                            increment_slot_number_failure()

                        if self.pending_drop_stmts > 0:
                            special_msg = "in replica_id "+str(replica_id)+" in client_id "+str(client_id)
                            drop_failure("client_request",request_id,special_msg)
                            return

                        if self.pending_crash_stmts > 0:
                            crash_failure()

                        if self.pending_sleep_statements > 0:
                            sleep_failure()

                shuttle_failures = get_pending_failures_if_exists(
                    client_id, request_id + retransmit_id, "shuttle")
                #print("outside "+str(len(shuttle_failures)) +" my replica_id is "+str(replica_id) +" for request_id "+str(request_id))
                for i in range(0,len(shuttle_failures)):
                    shuttle_failure = shuttle_failures[i]
                    #print("inside")
                    if shuttle_failure is not None:
                        logger.info("Trigger Exists:  in  replica=%s, trigger_name=shuttle with client_id=%s, request_id=%s, failure_to_be_executed=%s", str(
                            replica_id), str(client_id), str(request_id), str(shuttle_failure["failure_name"]))
                        update_failure_count(str(shuttle_failure["failure_name"]),shuttle_failure["failure_param"])

                        if self.pending_extra_op_stmts > 0:
                            extra_op_failure()

                        if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                            increment_slot_number_failure()

                        if self.pending_drop_stmts > 0:
                            special_msg = "in replica_id "+str(replica_id)+" in client_id "+str(client_id)
                            drop_failure("shuttle_failure",request_id,special_msg)                            
                            return

                        if self.pending_crash_stmts > 0:
                            crash_failure()

                        if self.pending_sleep_statements > 0:
                            sleep_failure()

                result = process_operation(operation)
                #order_proof = result_shuttle.get_order_proof_from_shuttle()
                order_proof = result_shuttle.get_clone_of_order_proof_from_shuttle()
                
                order_proof.set_replica_id_in_order_proof(replica_id)
                order_statement = OrderStatement(current_slot_number, operation, replica_id, self.private_key,client_id,request_id)
                # print("non_head_replica")
                order_proof.add_order_statment(replica_id,order_statement)
                history.add_order_proof_to_history(current_slot_number,order_proof)
                result_proof = ResultProof(operation, replica_id, result, self.private_key)
                result_shuttle.add_result_proof_to_shuttle(replica_id,result_proof)
                result_shuttle.add_order_statement_to_order_proof_in_shuttle(replica_id,order_statement)

                self.last_served_request_for_a_client[client_id] = ResultCache(client_id,request_id,result,replica_id,self.private_key,operation)
                logger.info("last_served_request_for_a_client: replica_id:%s,request_id:%s",str(replica_id),str(request_id))


                if self.pending_invalid_result_signatures > 0:
                    invalid_result_signature_failure(client_id,request_id,result_shuttle)
                if self.pending_change_operations > 0:
                    operation = change_operation_failure(client_request,client_id,request_id)
                if self.pending_invalid_order_stmts_signatures > 0:
                    invalid_order_statement_signature_failure(client_id,request_id,result_shuttle)


                if self.is_tail_replica is True:

                    if self.replica_state == self.Immutable:
                        return                  

                    #cloned_result_shuttle = copy.deepcopy(result_shuttle)
  
                    if self.pending_change_results > 0:
                        self.pending_change_result_failure_at_tail_replica = True 
                        change_result_in_result_shuttle_failure(client_id,request_id,result_shuttle)

                    if self.pending_drop_result_stmts > 0:
                        self.pending_drop_result_stmts_failure_at_tail_replica = True
                        drop_result_statement_of_head_replica_failure(client_id,request_id,result_shuttle)


                    send(('cache_result_shuttle', client_id, request_id,retransmit_id, result_shuttle, result), to=self)

                    #testing retransmit case when the request is processed but result didnot reach client
                    #and client got timedout cached result will be sent directly, requests wont be sent 
                    #to head_replica cached result
                    #add the below line .. 
                    # if int(client_id) == 0 and int(request_id) == 0 and int(replica_id) == 2 and retransmitted is None:
                    #     pass
                    # else:  
                    send(('result_shuttle', result_shuttle, result,replica_id,request_id),to=client_process)

                    logger.info("sent: 'result_shuttle' TO client_id=%s with result:%s, replica_id:%s,request_id:%s", str(client_id),str(result),str(replica_id),str(request_id))

                    #print(str(cache_key in self.send_acks_to_replicas) +" replica_id "+str(replica_id) +str(send_acks_to_replicas) )
                    if retransmitted is True or cache_key in send_acks_to_replicas:
                        # send result,result_proof to all the awaiting replicas
                        logger.info("sent: 'retransmitted_request_from_replica_to_head' TO all the replicas")
                        send(('retransmitted_request_from_replica_to_head',),to=replica_set.values())

                    # send(('cache_result_shuttle',client_id,request_id,retransmit_id,result_shuttle,result),to=self)
                    logger.info("sent: 'cache_result_shuttle' TO replica_id=%s, with client_id=%s, request_id=%s and result_shuttle", str(
                        replica_id), str(client_id), str(request_id))
                else:
                    next_replica = get_next_replica()
                    send(('perform_operation', client_request,result, result_shuttle, current_slot_number), to=next_replica)
                    logger.info("sent: 'perform_operation' TO next_replica=%s, with client_id=%s, request_id=%s, operation=%s,, sending to %s", str(
                        replica_id + 1), str(client_id), str(request_id), str(operation),str(next_replica))
                self.current_slot_number = self.current_slot_number + 1
                # return from result cache

    def check_in_order_proof(request_id):
        if request_id <= len(history.order_proof_for_each_slot) - 1:
            return True
        else:
            return False

    def get_pending_failures_if_exists(client_id, consolidated_request_id, trigger_name):
        #todo update according to the failure triggers with single parameter
        triggers_to_be_executed = []
        logger.info("checking_for_triggers: in replica_id=%s, with client_id=%s, request_id=%s,trigger_name=%s", str(
            replica_id), str(client_id), str(consolidated_request_id), str(trigger_name))
        to_be_removed = []
        for i in range(0, len(failure_triggers)):
            failure_trigger = failure_triggers[i]
            t_client_id = failure_trigger["client_id"]
            t_message_id = failure_trigger["message_id"]
            t_trigger_name = failure_trigger["trigger_name"]
            #logger.info("checking_for_triggers:@ in replica_id=%s, with client_id=%s, request_id=%s,trigger_name=%s", str(
            #    replica_id), str(t_client_id), str(t_message_id), str(t_trigger_name))
            if (client_id is  None or t_client_id is None or int(client_id) == int(t_client_id)) and int(t_message_id) == int(consolidated_request_id) and trigger_name == t_trigger_name:
                logger.info("checking_for_triggers: trigger found at replica_id=%s, with client_id=%s, request_id=%s,trigger_name=%s at index:%s", str(
                    replica_id), str(client_id), str(consolidated_request_id), str(trigger_name), str(i))
                #print("before "+str(failure_triggers))
                to_be_removed.append(i)
                #print("after "+str(failure_triggers))
                #print("trigger found is "+str(failure_trigger))
                triggers_to_be_executed.append(failure_trigger)

        for i in range(len(to_be_removed)-1,-1,-1):
            #print("before "+str(failure_triggers))
            del self.failure_triggers[to_be_removed[i]]
            #print("after "+str(failure_triggers))

        #print("returning triggers")
        return triggers_to_be_executed

    def update_failure_count(failure_name,failure_param):
        if failure_name == "change_operation":
            self.pending_change_operations = self.pending_change_operations + 1
        elif failure_name == "change_result":
            self.pending_change_results = self.pending_change_results + 1
        elif failure_name == "drop_result_stmt":
            self.pending_drop_result_stmts = self.pending_drop_result_stmts + 1
        elif failure_name == "crash":
            self.pending_crash_stmts = self.pending_crash_stmts + 1
        elif failure_name == "truncate_history":
            self.pending_truncate_history_statements = self.pending_truncate_history_statements + 1
        elif failure_name == "sleep":   
            self.pending_sleep_statements = self.pending_sleep_statements + 1
            self.sleep_time_periods.append(failure_param) 
        elif failure_name == "drop":
            self.pending_drop_stmts = self.pending_drop_stmts + 1
        elif failure_name == "increment_slot":            
            self.pending_increment_slot_stmts = self.pending_increment_slot_stmts + 1
        elif failure_name == "extra_op":
            self.pending_extra_op_stmts = self.pending_extra_op_stmts + 1
        elif failure_name == "invalid_order_sig":
            self.pending_invalid_order_stmts_signatures = self.pending_invalid_order_stmts_signatures + 1
        elif failure_name == "invalid_result_sig":
            self.pending_invalid_result_signatures = self.pending_invalid_result_signatures + 1
        elif failure_name == "drop_checkpt_stmts":
            self.pending_drop_checkpoint_stmts = self.pending_drop_checkpoint_stmts + 1

    def receive(msg=('retransmitted_request_from_replica_to_head',)):
        logger.info("retransmitted: request is successfully done for replica_id=%s", str(replica_id))        
        self.switch = 2

    def add_to_running_state(operation,running_state):
    
        logger.info("replica_id=%s is processing operations", str(replica_id))
        opcode = operation['operation']
        if opcode == "put":
            key = operation["key"]
            value = operation["value"]
            running_state[key] = value
            return running_state,"Success"
        elif opcode == "get":
            key = operation["key"]
            if key not in running_state:
                return "Error"
            value = running_state[key]
            return running_state,value
        elif opcode == "slice":
            key = operation["key"]
            if key not in running_state:
                return "Error"
            index1 = int(operation["value1"])
            index2 = int(operation["value2"])
            value = running_state[key]
            value = value[index1:index2]
            running_state[key] = value
            return running_state,value
        elif opcode == "append":
            key = operation["key"]
            if key not in running_state:
                return "Error"
            value = operation["value"]
            #print("operation append value is"+str(operation["value"]))
            value = running_state[key] + value
            running_state[key] = value
            return running_state,"Success"

    def receive(msg=('get_running_state',running_state_id),from_=olympus):
        logger.info("get_running_state: from replica_id=%s", str(replica_id))  
        running_state_failures = get_pending_failures_if_exists(None, running_state_id, "get_running_state")
        for running_state_failure in running_state_failures:
            if running_state_failure is not None:
                logger.info("Trigger Exists: in  replica=%s, trigger_name=get_running_state with running_state_id=%s, failure_to_be_executed=%s", str(
                    replica_id), str(running_state_id), str(running_state_failure["failure_name"]))
                update_failure_count(str(running_state_failure["failure_name"]),running_state_failure["failure_param"])

                if self.pending_extra_op_stmts > 0:
                    extra_op_failure()

                if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                    increment_slot_number_failure()

                if self.pending_drop_stmts > 0:
                    drop_failure("get_running_state",running_state_id)
                    empty_running_state = {}
                    send(('running_state_from_replica',replica_id,empty_running_state),to = olympus)
                    return

                if self.pending_crash_stmts > 0:
                    crash_failure()

                if self.pending_sleep_statements > 0:
                    sleep_failure()


        running_state = caughtup_message.get_running_state() 
        send(('running_state_from_replica',replica_id,running_state),to = olympus)

    def receive(msg=('new_configuration',running_state),from_=olympus):
        logger.info("new_configuration: saving running_state sent by olympus at running_state=%s replica_id=%s",str(running_state), str(replica_id))  

        if self.pending_extra_op_stmts > 0:
            extra_op_failure()

        if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
            increment_slot_number_failure()

        self.data_object = running_state 

        
    def receive(msg=('perform_catchup_to_maximal_order_proof',catchup_message,catchup_msg_identifier),from_=olympus):
        logger.info("perform_catchup_to_maximal_order_proof: to replica_id=%s", str(replica_id))   
        catchup_msg_failures = get_pending_failures_if_exists(None, catchup_msg_identifier, "catch_up")
        for catchup_msg_failure in catchup_msg_failures:
            if catchup_msg_failure is not None:
                logger.info("Trigger Exists: in  replica=%s, trigger_name=catch_up with catchup_msg_identifier=%s, failure_to_be_executed=%s", str(
                    replica_id), str(catchup_msg_identifier), str(catchup_msg_failure["failure_name"]))
                update_failure_count(str(catchup_msg_failure["failure_name"]),catchup_msg_failure["failure_param"])

                if self.pending_extra_op_stmts > 0:
                    extra_op_failure()

                if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                    increment_slot_number_failure()

                if self.pending_drop_stmts > 0:
                    drop_failure("catchup_message",catchup_msg_identifier)
                    caughtup_message = CaughtUpMessage(-1)
                    send(('caughtup_message',replica_id,caughtup_message),to = olympus)
                    return

                if self.pending_crash_stmts > 0:
                    crash_failure()

                if self.pending_sleep_statements > 0:
                    sleep_failure()

        temp_last_served_request_for_a_client = copy.deepcopy(last_served_request_for_a_client)
        running_state = copy.deepcopy(self.data_object)     
        slot_ids = catchup_message.get_slot_ids()
        logger.info("slot_ids "+str(slot_ids) +" replica_id "+str(replica_id) +" history.slots "+str(self.history.get_slots())+" running_state "+str(running_state))
        for slot_id in slot_ids:
            catchup_statement = catchup_message.get_catchup_statement_at_slot_id(slot_id)
            operation = catchup_statement.get_operation_in_catchup_statement()
            client_id = catchup_statement.get_operation_requested_client_id()
            request_id = catchup_statement.get_request_id_sent_by_client()
            running_state,result = add_to_running_state(operation,running_state)
            temp_last_served_request_for_a_client[client_id] = ResultCache(client_id,request_id,result,replica_id,self.private_key,operation)
            logger.info("last_served_request_for_a_client "+str(temp_last_served_request_for_a_client[0].get_result())+" at replica_id "+str(replica_id)+" request_id is"+str(request_id))
        caughtup_message = CaughtUpMessage(replica_id)
        caughtup_message.add_running_state(running_state,private_key)
        for client_id in temp_last_served_request_for_a_client:
            result_statement = temp_last_served_request_for_a_client[client_id]
            caughtup_message.add_last_served_request_result_statement(client_id,result_statement)

        self.caughtup_message =caughtup_message

        logger.info(" replica_id "+str(replica_id)+" running_state "+str(running_state))
        send(('caughtup_message',replica_id,caughtup_message),to = olympus)

    #def receive(msg=('initiating_retransmit_request', client_id, request_id, operation, client_process, retransmit_id)):
    def receive(msg=('initiating_retransmit_request', client_request),from_ = valid_process):

        client_id = client_request.get_client_id()
        request_id = client_request.get_request_id()
        operation = client_request.get_operation()
        client_process = client_request.get_client_process_info()
        retransmit_id = client_request.get_retransmit_id()
        
        #output("inside retransmit request from "+str(client_process)+" at replica_id "+str(replica_id))
        logger.info("received: 'initiating_retransmit_request' by replica_id=%s, with client_id=%s, request_id=%s, operation=%s", str(
            replica_id), str(client_id), str(request_id), str(operation))
        
        if self.replica_state == self.Immutable:
            logger.info("replica is immutable,wont process requests anymore")
            return

        if is_registered_client(client_id) is False:
            # error case
            #output('malicious client found')
            logger.warning("MALICIOUS client found")
        else:
            if self.pending_extra_op_stmts > 0:
                extra_op_failure()

            cache_key = '00000'+str(client_id)+'11111' + str(request_id)
            #output("replica_id"+ str(replica_id)+" is processing the retransmitted operation FROM client_id:"+ str(client_id)+" request id is"+str(request_id))
            logger.info("replica_id=%s is processing the retransmitted operation FROM client_id=%s", str(
                replica_id), str(client_id))
            cached_object = check_in_result_cache(request_id, client_id)
            #print("cached_object" +str(cached_object))
            if cached_object is not None and cached_object != True:
                #output("***found retransmit request from "+str(client_process)+" at replica_id "+str(replica_id))
                result_shuttle = cached_object.result_shuttle
                result = cached_object.result
                send(('result_shuttle', result_shuttle, result,replica_id,request_id), to=client_process)
                logger.info("sent: 'result_shuttle' TO client_id=%s, with result shuttle and reslut=%s", str(
                    client_id), str(result))
                # todo
            elif self.is_head_replica is True:
        

                if self.pending_increment_slot_stmts > 0:
                    increment_slot_number_failure()

                send(('send_retransmitted_status',cache_key,replica_id),to = tail_replica)
                self.retransmit_acknowledged = 1
                await(self.retransmit_acknowledged == 2)
                #output(" not found in cache retransmitting the request")
                if check_in_order_proof(request_id) is False:
                    # this is a new operation
                    #output("head request request also sent")
                    send(('perform_operation', client_request,None,None,None), to=head_replica)
                    # send(('perform_operation', client_id, request_id, operation,
                    #       client_process, None, None, None, True, retransmit_id), to=head_replica)
                    self.switch = 1
                    logger.info("retransmitting_to_head_replica: 'perform_operation' with client_id=%s, request_id=%s, operation=%s TO head_replica", str(
                        client_id), str(request_id), str(operation))
                    if await(self.switch == 2):
                        # received response before the timer got expired
                        pass
                    elif timeout(self.replica_timeout):
                        #output("timeout occurred, provable case of misbehaviour send reconfg request")
                        send(('reconfigure_request',replica_id), to=olympus)

                        logger.warning("initiating_retransmit_request: retransmit failed for client_id:"+str(client_id)+" request_id:"+str(request_id) +" retransmit_id: "+str(retransmit_id)+" send reconfiguration request")

                else:
                    # start timer
                    # here the operation has already been scheduled so just starting a timer
                    # send(('start_timer_for_request',client_id,request_id),to=self)
                    logger.info("head_replica:waiting for operation to processed with client_id=%s, request_id=%s, operation=%s ,retransmit_id=%s", str(
                        client_id), str(request_id), str(operation),str(retransmit_id))
                    self.switch = 1
                    if await(self.switch == 2):
                        # received response before the timer got expired
                        pass
                    elif timeout(self.replica_timeout):
                        send(('reconfigure_request',replica_id), to=olympus)
                        #output("timeout occurred, provable case of misbehaviour send reconfg request")
                        logger.warning("initiating_retransmit_request: retransmit failed for client_id:"+str(client_id)+" request_id:"+str(request_id) +" retransmit_id: "+str(retransmit_id)+" send reconfiguration request")
            
            else:
                logger.info("send_retransmitted_status: cache_key "+str(cache_key) +" at replica_id "+str(replica_id))
                send(('send_retransmitted_status',cache_key,replica_id),to = tail_replica)
                self.retransmit_acknowledged = 1
                await(self.retransmit_acknowledged == 2)

                #output("in non head replica " +" at replica_id "+str(replica_id))
                # checking if the request is retransmitted or new request

                # for non head replicas
                # start timer and send the request to head
                # send(('start_timer_for_request',client_id,request_id),to=head_replica)
                logger.info("retransmitting_to_head_replica: 'perform_operation' with client_id=%s, request_id=%s, operation=%s TO head_replica", str(
                    client_id), str(request_id), str(operation))

                send(('perform_operation', client_request,None,None,None), to=head_replica)
                # send(('perform_operation', client_id, request_id, operation,
                #       client_process, None, None, None, True, retransmit_id), to=head_replica)
                #output("in non head replica sent")
                self.switch == 1
                if await(self.switch == 2):
                    # received response before the timer got expired
                    # send(('served_retransmit_request',result,result_shuttle,current_clock))
                    pass
                elif timeout(self.replica_timeout):
                    send(('reconfigure_request',replica_id), to=olympus)
                    #output("timeout occurred, provable case of misbehaviour send reconfg request")
                    logger.warning("initiating_retransmit_request: retransmit failed for client_id:"+str(client_id)+" request_id:"+str(request_id) +" retransmit_id: "+str(retransmit_id)+" send reconfiguration request")
    # def receive(msg=('retransmitted_request_from_replica_to_head',result,result_shuttle,client_process)):
    #	send(('result_shuttle',result,result_shuttle),to=client_process)

    def receive(msg=('cache_result_shuttle', client_id, request_id, retransmit_id, result_shuttle, result)):
        if self.replica_state == self.Immutable:
            logger.info("inside: cache_result_shuttle, replica_id "+str(replica_id)+" is immutable "+" caching will stop")
            return

        logger.info("received: 'cache_result_shuttle' with client_id=%s, request_id=%s,  at replica=%s result_shuttle and result=%s", str(
            client_id), str(request_id), str(replica_id), str(result))

        if validate_result_shuttle(result_shuttle, client_id, request_id, replica_id) is False:
            logger.info("result validation failed for request_id=%s FROM client_id=%s", str(
                    request_id), str(client_id))
            return
        else:
            logger.info("result validation successful")

        cache_key = '00000'+str(client_id)+'11111' + str(request_id)
        cachedObject = CachedResult(result, result_shuttle)
        #output("cached the result "+str(result) +" and result_shuttle "+str(result_shuttle)+" at replica_id "+str(replica_id)+" client_id "+str(client_id)+" for request_id "+str(request_id) )
        self.result_cache[cache_key] = cachedObject

        result_shuttle_failures = get_pending_failures_if_exists(
            client_id, request_id + retransmit_id, "result_shuttle")
        for result_shuttle_failure in result_shuttle_failures:
            if result_shuttle_failure is not None:
                logger.info("Trigger Exists:  in  replica=%s, trigger_name=result_shuttle with client_id=%s, request_id=%s, failure_to_be_executed=%s", str(
                    replica_id), str(client_id), str(request_id), str(result_shuttle_failure["failure_name"]))
                update_failure_count(str(result_shuttle_failure["failure_name"]),result_shuttle_failure["failure_param"])

                if self.pending_extra_op_stmts > 0:
                    extra_op_failure()

                if self.is_head_replica is True and self.pending_increment_slot_stmts > 0:
                    increment_slot_number_failure()

                if self.pending_drop_stmts > 0:
                    special_msg = "in replica_id "+str(replica_id)+" in client_id "+str(client_id)
                    drop_failure("result_shuttle",request_id,special_msg)
                    return

                if self.pending_crash_stmts > 0:
                    crash_failure()

                if self.pending_sleep_statements > 0:
                    sleep_failure()

        if self.pending_change_results > 0 or self.pending_change_result_failure_at_tail_replica is True:
            self.pending_change_result_failure_at_tail_replica = False
            change_result_in_result_shuttle_failure(client_id,request_id,result_shuttle)
        if self.pending_drop_result_stmts > 0:
            self.pending_drop_result_stmts_failure_at_tail_replica = False
            drop_result_statement_of_head_replica_failure(client_id,request_id,result_shuttle)

        if self.is_head_replica is False:
            prev_replica = get_prev_replica()
            send(('cache_result_shuttle', client_id, request_id,
                  retransmit_id, result_shuttle, result), to=prev_replica)
            logger.info("sent: 'cache_result_shuttle' with client_id=%s, request_id=%s, result=%s TO previous replica_id=%s", str(
                client_id), str(request_id), str(result), str(replica_id - 1))
        else:
            #output("Caching done for all replicas for request_id "+str(request_id)+" and client_id "+str(client_id))
            logger.info("CACHING done for all replicas for request_id=%s FROM client_id=%s", str(
                request_id), str(client_id))

    def receive(msg=('store_keys', public_key, private_key, public_keys)):
        logger.info("received: 'store_keys' from Olympus")
        self.public_key = public_key
        self.private_key = private_key
        self.public_keys = public_keys
        send(('KeysFound',), to=self)
        logger.info("sent: 'KeysFound' to self")

    def run():
        #print("reincarnation "+str(replica_id))
        await(received(('KeysFound',), from_=self))
        await(received(('done',), from_=self))
